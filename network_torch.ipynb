{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a neural network based on the modified U-Net architecture found in the DeepHarmony paper (as pictured below). In addition, it features batch normalization layers integrated within the network and a compound loss function made up of MS-SSIM and L1. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn \n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from matplotlib import pyplot as plt\n",
    "from Preprocessing import Preprocessing\n",
    "import os\n",
    "import SimpleITK as sitk\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Definition of the Network Class, including loss function definition and convolution definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of Neural Network\n",
    "class Unet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        self.o1 = self.convolution(1, 16, 16)\n",
    "        self.o2 = self.down_convolution(16, 16, 16)\n",
    "        self.o3 = self.convolution(16, 32, 32)\n",
    "        self.o4 = self.down_convolution(32, 32, 32)\n",
    "        self.o5 = self.convolution(32, 64, 64)\n",
    "        self.o6 = self.down_convolution(64, 64, 64)\n",
    "        self.o7 = self.convolution(64, 128, 128)\n",
    "        self.o8 = self.down_convolution(128, 128, 128)\n",
    "        self.o9 = self.convolution(128, 256, 256)\n",
    "        self.o10 = self.up_convolution(256, 256, 256)\n",
    "        self.o12 = self.convolution(256, 128, 128)\n",
    "        self.o13 = self.up_convolution(128, 128, 128)\n",
    "        self.o15 = self.convolution(128, 64, 64)\n",
    "        self.o16 = self.up_convolution(64, 64, 64)\n",
    "        self.o18 = self.convolution(64, 32, 32)\n",
    "        self.o19 = self.up_convolution(32, 32, 32)\n",
    "        self.o21 = self.convolution(32, 16, 16)\n",
    "        self.o23 = self.final_convolution(16, 1)\n",
    "    \n",
    "    # forward pass\n",
    "    def forward(self, image):\n",
    "\n",
    "        # left\n",
    "        x1 = self.o1(image)\n",
    "\n",
    "        x2 = self.o2(x1)\n",
    "        \n",
    "        x3 = self.o3(x2)\n",
    "        \n",
    "        x4 = self.o4(x3)\n",
    "        \n",
    "        x5 = self.o5(x4)\n",
    "        \n",
    "        x6 = self.o6(x5)\n",
    "        \n",
    "        x7 = self.o7(x6)\n",
    "        \n",
    "        x8 = self.o8(x7)\n",
    "        \n",
    "        x9 = self.o9(x8)\n",
    "        \n",
    "\n",
    "        # right\n",
    "        x10 = self.o10(x9)\n",
    "        \n",
    "        y10 = self.crop_tensor(x10, x7)\n",
    "        x11 = torch.cat([x10, y10], 1)\n",
    "        \n",
    "        x12 = self.o12(x11)\n",
    "        \n",
    "        x13 = self.o13(x12)\n",
    "\n",
    "        y13 = self.crop_tensor(x13, x5)\n",
    "        x14 = torch.cat([x13, y13], 1)\n",
    "\n",
    "        x15 = self.o15(x14)\n",
    "\n",
    "        x16 = self.o16(x15)\n",
    "\n",
    "        y16 = self.crop_tensor(x16, x3)\n",
    "        x17 = torch.cat([x16, y16], 1)\n",
    "\n",
    "        x18 = self.o18(x17)\n",
    "\n",
    "        x19 = self.o19(x18)\n",
    "\n",
    "        y19 = self.crop_tensor(x19, x1)\n",
    "        x20 = torch.cat([x19, y19], 1)\n",
    "\n",
    "        x21 = self.o21(x20)\n",
    "\n",
    "        x22 = torch.cat([x21, image], 1)\n",
    "\n",
    "        x23 = self.o23(x22)\n",
    "\n",
    "        return x23\n",
    "    \n",
    "    def convolution(self, in_c, out_c, num_features):\n",
    "        run = nn.Sequential(\n",
    "            nn.Conv2d(in_c, out_c, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features)\n",
    "        )\n",
    "        return run\n",
    "    \n",
    "    def down_convolution(self, in_c, out_c, num_features):\n",
    "        run = nn.Sequential(\n",
    "            nn.Conv2d(in_c, out_c, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features)\n",
    "        )\n",
    "        return run\n",
    "\n",
    "    def up_convolution(self, in_c, out_c, num_features):\n",
    "        run = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_c, out_c, 4, 0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features),\n",
    "        )\n",
    "        return run\n",
    "\n",
    "    def final_convolution(self, in_c, out_c):\n",
    "        run = nn.Sequential(\n",
    "            nn.Conv2d(in_c, out_c, kernel_size=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        return run\n",
    "\n",
    "    def crop_tensor(self, target_tensor, tensor):\n",
    "        target_size = target_tensor.size()[2]\n",
    "        tensor_size = tensor.size()[2]\n",
    "        delta = tensor_size - target_size\n",
    "        delta = delta // 2\n",
    "\n",
    "        return tensor[:, :, delta:tensor_size- delta, delta:tensor_size-delta]\n",
    "    \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Data, running preprocessing programs, and Splitting into training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = Preprocessing(\"./data/modified/\", \"./data/preprocessed/\")\n",
    "\n",
    "# MRI dataset with training, testing and validation \n",
    "class MRIData(Dataset):\n",
    "    def __init__(self):\n",
    "        self.training = []\n",
    "        self.testing = []\n",
    "        self.validation = []\n",
    "        self.input_files = os.listdir(preprocessing.input_folder)\n",
    "\n",
    "        for i in range(179):\n",
    "            self.training.append(self.input_files[i])\n",
    "\n",
    "        for i in range(179, 223):\n",
    "            self.testing.append(self.input_files[i])\n",
    "\n",
    "        for i in range (223, 267):\n",
    "            self.validation.append(self.input_files[i])    \n",
    "    \n",
    "    def __getitem__(self, dataset, index):\n",
    "        \n",
    "        if dataset == \"training\":\n",
    "            scan_path = self.training[index]\n",
    "            scan = sitk.ReadImage(scan_path, sitk.sitkFloat32)\n",
    "            return scan\n",
    "        if dataset == \"testing\":\n",
    "            scan_path = self.testing[index]\n",
    "            scan = sitk.ReadImage(scan_path, sitk.sitkFloat32)\n",
    "            return scan\n",
    "        if dataset == \"validation\":\n",
    "            scan_path = self.validation[index]\n",
    "            scan = sitk.ReadImage(scan_path, sitk.sitkFloat32)\n",
    "            return scan \n",
    "\n",
    "    def __len__(self, dataset):\n",
    "        if dataset == \"training\":\n",
    "            return len(self.training)\n",
    "        if dataset == \"testing\":\n",
    "            return len(self.testing)\n",
    "        if dataset == \"validation\":\n",
    "            return len(self.validation)\n",
    "        \n",
    "\n",
    "mriData = MRIData()\n",
    "trainingLoader = DataLoader(mriData.training, batch_size=12, shuffle=True)\n",
    "testingLoader = DataLoader(mriData.testing, batch_size=12, shuffle=True)\n",
    "validationLoader = DataLoader(mriData.validation, batch_size=12, shuffle=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "dh = Unet()\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(dh.parameters(), lr=0.001)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
