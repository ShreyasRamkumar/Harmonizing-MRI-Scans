{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a neural network based on the modified U-Net architecture found in the DeepHarmony paper (as pictured below). In addition, it features batch normalization layers integrated within the network and a compound loss function made up of MS-SSIM and L1. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn \n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Definition of the Network Class, including loss function definition and convolution definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet(nn.Module):\n",
    "    def __init__(self, input_folder, output_folder):\n",
    "        super().__init__()\n",
    "        self.input_folder = input_folder\n",
    "        self.output_folder = output_folder\n",
    "        self.input_size = (512, 512, 1)\n",
    "\n",
    "    def convolution(self, input_image, in_channels, out_channels, kernel_size, stride):\n",
    "        conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride)(input_image)\n",
    "        bn = nn.BatchNorm2d(num_features=1, eps=0.0001)(conv)\n",
    "        return bn\n",
    "\n",
    "    def down_convolution(self, inp, n_filters):\n",
    "        conv = nn.Conv2D(n_filters, (4, 4), activation=\"relu\", padding=\"same\", strides=(2,2), kernel_initializer=\"he_normal\")(inp)\n",
    "        bn = bn = nn.BatchNorm2d(num_features=1, eps=0.0001)(conv)\n",
    "        return bn\n",
    "\n",
    "    def up_convolution(self, inp, n_filters, conv_features):\n",
    "        deconvolution = nn.Conv2d(n_filters, (4, 4), activation = 'relu', padding = 'same', strides=(0.5, 0.5), kernel_initializer = 'he_normal')(inp)\n",
    "        concatenation = torch.cat([conv_features, deconvolution], axis=3)\n",
    "        return concatenation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Data, running preprocessing programs, and Splitting into training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = Preprocessing(\"./data/modified/\", \"./data/preprocessed/\")\n",
    "training = []\n",
    "testing = []\n",
    "validation = []\n",
    "input_files = os.listdir(preprocessing.input_folder)\n",
    "\n",
    "for i in range(179):\n",
    "    training.append(input_files[i])\n",
    "\n",
    "for i in range(179, 223):\n",
    "    testing.append(input_files[i])\n",
    "\n",
    "for i in range (223, 267):\n",
    "    validation.append(input_files[i])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
